# paper-list
## VLM
### GalLoP: Learning Global and Local Prompts  for Vision-Language Models
code-link: https://github.com/MarcLafon/gallop  
ECCV 2024  
summary：GalLoP 通过稀疏选择 + 特征对齐学习强判别力的局部提示，并借助prompt dropout + 多尺度策略增强全局/局部提示的多样性，从而在保持高分类准确率的同时显著提升模型鲁棒性，打破了准确率与鲁棒性的传统权衡。


## FL
### FedMVP: Federated Multimodal Visual Prompt Tuning for Vision-Language  Models
code-link: https: //github.com/mainaksingha01/FedMVP    
ICCV 2025  
summary：FedMVP提出了一种联邦多模态视觉提示调优框架，通过PromptFormer模块利用交叉注意力机制协同对齐LLM生成的文本属性特征和视觉patch嵌入，在仅训练少量提示参数而冻结预训练CLIP模型的情况下，实现了联邦non-IID场景下视觉-语言模型对未见类别和领域的高效泛化适应。
